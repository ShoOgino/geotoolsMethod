    /**
     * Apply paging. It's pretty straight forward except when the view is denormalised, because we don't know
     * how many rows would represent 1 feature.
     * @param query
     * @param sql
     * @param pkColumnNames
     * @param typeName
     * @param tableNames
     * @param filterToSQL
     * @param filter
     * @return
     * @throws SQLException
     * @throws FilterToSQLException
     * @throws IOException
     */
    private Collection<String> applyPaging(JoiningQuery query, StringBuffer sql,
            Set<String> pkColumnNames, String typeName, Set<String> tableNames
            , FilterToSQL filterToSQL, Filter filter) throws SQLException, FilterToSQLException, IOException {
        Collection<String> ids = Collections.EMPTY_LIST;
        if (getDataStore().dialect.isLimitOffsetSupported()) {
            int startIndex = query.getStartIndex() == null ? 0 : query.getStartIndex();
            if (query.isDenormalised()) {
                // if not denormalised, use the maxFeatures and offset in the query
                int maxFeatures = query.getMaxFeatures();
                if (startIndex > 0 || maxFeatures != Query.DEFAULT_MAX) {
                    // handle denormalised grouping by id, or if unspecified, PK
                    if (!query.getIds().isEmpty()) {
                        ids = query.getIds();
                    } else {
                        ids = pkColumnNames;
                    }
                    for (String id : ids) {
                        sql.append(" INNER JOIN (");
                        StringBuffer topIds = new StringBuffer();
                        topIds.append("SELECT DISTINCT ");
                        encodeColumnName(id, typeName, topIds, query.getHints());
                        topIds.append(" FROM ");
                        getDataStore().encodeTableName(typeName, topIds,
                                query.getHints());
                        // apply filter
                        if (filter != null) {
                            filterToSQL.setFieldEncoder(new JoiningFieldEncoder(typeName));
                            topIds.append(" ").append(filterToSQL.encodeToString(filter));
                        }
                         // postgis doesn't guarantee sorting unless specified
                        topIds.append(" ORDER BY ");
                        encodeColumnName(id, typeName, topIds, query.getHints());
                        // apply TOP using limit offset
                        getDataStore().dialect.applyLimitOffset(topIds, maxFeatures, startIndex);
                        sql.append(topIds);
                        sql.append(") ");
                        String alias = createAlias(typeName, tableNames);
                        tableNames.add(alias);
                        getDataStore().dialect.encodeTableName(alias, sql);                        
                        sql.append(" ON (");
                        encodeColumnName(id, typeName, sql, query.getHints());
                        sql.append(" = ");
                        getDataStore().dialect.encodeColumnName(alias, id, sql);
                        sql.append(" ) ");
                    }
                    if (!ids.isEmpty()) {
                        // we've applied startIndex on the ids, so we don't need to apply this to the main query
                        query.setStartIndex(0);
                        query.setMaxFeatures(Query.DEFAULT_MAX);
                    }
                }
            }
        }
        return ids;
    }


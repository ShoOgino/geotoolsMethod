    protected  FeatureReader<SimpleFeatureType, SimpleFeature> getReaderInternal(Query query) throws IOException {
        // split the filter
        Filter[] split = splitFilter(query.getFilter());
        Filter preFilter = split[0];
        Filter postFilter = split[1];
        
        // rebuild a new query with the same params, but just the pre-filter
        DefaultQuery preQuery = new DefaultQuery(query);
        preQuery.setFilter(preFilter);
        
        // Build the feature type returned by this query. Also build an eventual extra feature type
        // containing the attributes we might need in order to evaluate the post filter
        SimpleFeatureType querySchema;
        SimpleFeatureType returnedSchema;
        if(query.getPropertyNames() == Query.ALL_NAMES) {
            returnedSchema = querySchema = getSchema();
        } else {
            returnedSchema = SimpleFeatureTypeBuilder.retype(getSchema(), query.getPropertyNames());
            FilterAttributeExtractor extractor = new FilterAttributeExtractor(getSchema());
            postFilter.accept(extractor, null);
            String[] extraAttributes = extractor.getAttributeNames();
            if(extraAttributes == null || extraAttributes.length == 0) {
                querySchema = returnedSchema;
            } else {
                List<String> allAttributes = new ArrayList<String>(Arrays.asList(query.getPropertyNames())); 
                for (String extraAttribute : extraAttributes) {
                    if(!allAttributes.contains(extraAttribute))
                        allAttributes.add(extraAttribute);
                }
                String[] allAttributeArray =  (String[]) allAttributes.toArray(new String[allAttributes.size()]);
                querySchema = SimpleFeatureTypeBuilder.retype(getSchema(), allAttributeArray);
            }
        }
        
        //grab connection
        Connection cx = getDataStore().getConnection(getState());
        
        //create the reader
        FeatureReader<SimpleFeatureType, SimpleFeature> reader;
        
        try {
            // this allows PostGIS to page the results and respect the fetch size
            if(getState().getTransaction() == Transaction.AUTO_COMMIT) {
                cx.setAutoCommit(false);
            }
            
            SQLDialect dialect = getDataStore().getSQLDialect();
            if ( dialect instanceof PreparedStatementSQLDialect ) {
                PreparedStatement ps = getDataStore().selectSQLPS(querySchema, preQuery, cx);
                reader = new JDBCFeatureReader( ps, cx, this, querySchema, query.getHints() );
            } else {
                //build up a statement for the content
                String sql = getDataStore().selectSQL(querySchema, preQuery);
                getDataStore().getLogger().fine(sql);
    
                reader = new JDBCFeatureReader( sql, cx, this, querySchema, query.getHints() );
            }
        } catch (Exception e) {
            // close the connection 
            getDataStore().closeSafe(cx);
            // safely rethrow
            throw (IOException) new IOException().initCause(e);
        }
        

        // if post filter, wrap it
        if (postFilter != null && postFilter != Filter.INCLUDE) {
            reader = new FilteringFeatureReader<SimpleFeatureType, SimpleFeature>(reader,postFilter);
            if(!returnedSchema.equals(querySchema))
                reader = new ReTypeFeatureReader(reader, returnedSchema);
        }

        return reader;
    }


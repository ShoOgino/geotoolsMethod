    /** Checking time get extracted from remote URL too. */
    @Test
    public void testTimeDimensionMosaic() throws Exception {

        final File workDir = prepareWorkingDir("emptycog.zip", "timeMosaic", "");
        try (FileWriter out =
                new FileWriter(
                        new File(TestData.file(this, "."), "/timeMosaic/datastore.properties"))) {
            out.write("database=cogmosaic\n");
            out.write(ImageMosaicReaderTest.H2_SAMPLE_PROPERTIES);
            out.flush();
        }
        try (FileWriter out =
                new FileWriter(
                        new File(TestData.file(this, "."), "/timeMosaic/timeregex.properties"))) {
            out.write("regex=[0-9]{8}");
            out.flush();
        }
        try (FileWriter out =
                new FileWriter(
                        new File(TestData.file(this, "."), "/timeMosaic/indexer.properties"),
                        true)) {
            out.write("\nPropertyCollectors=TimestampFileNameExtractorSPI[timeregex](time)");
            out.write("\nTimeAttribute=time");
            out.write("\nSchema=location:String,time:java.util.Date,*the_geom:Polygon\n");
            out.flush();
        }

        final AbstractGridFormat IMAGE_MOSAIC_FORMAT = new ImageMosaicFormat();
        ImageMosaicReader reader = (ImageMosaicReader) IMAGE_MOSAIC_FORMAT.getReader(workDir);
        GranuleCatalog originalCatalog = reader.granuleCatalog;

        try {
            // now go and harvest 2 granules
            List<URL> urls = new LinkedList<>();
            urls.add(
                    new URL(
                            "https://s3-us-west-2.amazonaws.com/landsat-pds/c1/L8/153/075/LC08_L1TP_153075_20190429_20190429_01_RT/LC08_L1TP_153075_20190429_20190429_01_RT_B1.TIF"));
            urls.add(
                    new URL(
                            "https://s3-us-west-2.amazonaws.com/landsat-pds/c1/L8/153/075/LC08_L1TP_153075_20190515_20190515_01_RT/LC08_L1TP_153075_20190515_20190515_01_RT_B3.TIF"));
            List<HarvestedSource> summary = reader.harvest(null, urls, null);
            assertSame(originalCatalog, reader.granuleCatalog);
            assertEquals(2, summary.size());

            assertEquals("true", reader.getMetadataValue("HAS_TIME_DOMAIN"));
            assertEquals(
                    "2019-04-29T00:00:00.000Z", reader.getMetadataValue("TIME_DOMAIN_MINIMUM"));
            assertEquals(
                    "2019-05-15T00:00:00.000Z", reader.getMetadataValue("TIME_DOMAIN_MAXIMUM"));
        } finally {
            reader.dispose();
        }
    }

